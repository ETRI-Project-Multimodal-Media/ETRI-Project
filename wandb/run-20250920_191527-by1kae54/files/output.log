Loading LongVALE-LLM from base model...
`torch_dtype` is deprecated! Use `dtype` instead!
You are using a model of type llama to instantiate a model of type LongVALE-LLM. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards: 100%|███████████████████████████████| 2/2 [00:00<00:00, 73.98it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
load visual mlp: checkpoints/vtimellm_stage1_mm_projector.bin
Loading stage2 weights...
Loading LoRA weights...
Merging stage2 weights...
Loading stage3 weights...
Loading LoRA weights...
Merging stage3 weights...
  0%|                                                               | 0/1171 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/kylee/LongVALE/longvalellm/eval/eval.py", line 122, in <module>
    answer = inference(model, video_features, audio_features, asr_features, "<video>\n " + query, tokenizer)
  File "/home/kylee/LongVALE/longvalellm/eval/../../longvalellm/inference.py", line 38, in inference
    output_ids = model.generate(
  File "/home/kylee/anaconda3/envs/longvale/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/kylee/anaconda3/envs/longvale/lib/python3.10/site-packages/transformers/generation/utils.py", line 2539, in generate
    result = self._sample(
  File "/home/kylee/anaconda3/envs/longvale/lib/python3.10/site-packages/transformers/generation/utils.py", line 2867, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/kylee/anaconda3/envs/longvale/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/kylee/anaconda3/envs/longvale/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: LongVALELLMLlamaForCausalLM.forward() got an unexpected keyword argument 'cache_position'
